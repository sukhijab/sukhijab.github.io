<!DOCTYPE html>
---
layout: default
---

<h1> Globally Optimal Safe Robot Learning in Higher Dimensioms</h1>
<p>This is a blog about our recent work on GoSafe.</p>
<p> A recurring and time-consuming problem in control is the tuning of controller parameters.
Learning policies from data enables the automation of this tedious process. However, many of the data based learning approaches provide no guarantees on the safety of the system during the optimizing process. This becomes a major concern when optimizing directly on hardware systems and can lead to hardware damage. 
Bayesian optimization is a sample-efficient black-box optimization method, which has been successfully applied to perform parameter tuning for robotic systems without risking system failure. Existing approaches such as SafeOpt are able to find optimal parameters while providing high probability safety guarantees. However, they are restricted to a local region around an initially given safe controller parameterization. Thus, the optimum they find might only be a local optimum.
GoSafe on the other hand can search for safe parameters globally while also providing the same safety guarantees. It achieves this by learning safe backup parameters for different states which are triggered during global exploration in case of a potential failure. Therefore, GoSafe does not only explore the space of potential controller parameters but also the state space. This imposes constraints on the algorithm's practical application for general robotic systems with high dimensional state space. In particular, (i) this additional exploration requires more experiments on hardware, which is time-consuming and can cause wear,  (ii) as more experiments are conducted, more data is collected, which is difficult to handle for GoSafe since it relies on Gaussian process inference which scales cubically with the number of data points. 
In this work, we derive extensions to GoSafe which allow us to tackle problems with higher dimensions. Specifically, under mild assumptions such as the Markov property of the underlying system, we show that we can gather more information from our experiments and that way significantly reduce the number of experiments. Furthermore, we show that a subset selection scheme can be applied to reduce the computational cost of Gaussian process inference, while still retaining the safety and convergence guarantees.
Next, to perform Bayesian optimization in higher dimensions we use an adaptive discretization based on particle swarms. Finally, we propose practical modifications to the algorithm and provide conditions under which they can be applied. Our proposed modifications hold for a variety of tasks, are sample efficient and have a low computational cost.
We apply our method to tune a operational space impedance controller for the Franka Emika Panda robot arm in hardware and simulation. </p>
 <video width="720" height="540" class="demoVideo" controls>
      <source src="videos/hardware_experiments.mp4" type=video/mp4>
      <source src="videos/hardware_experiments.webm" type="video/webm">
      Your browser does not support the video tag.
</video>
<h2> References: </h2>
<p> Globally Optimal Safe Robot Learning: https://arxiv.org/abs/2105.13281 </p>
<p> Safe controller optimization for quadrotors with Gaussian processes: https://ieeexplore.ieee.org/document/7487170 </p>
<p> Bayesian Optimization with Safety Constraints: Safe and Automatic Parameter Tuning in Robotics: https://arxiv.org/abs/1602.04450 </p>
<p> Safe Exploration for Optimization with Gaussian Processes: http://proceedings.mlr.press/v37/sui15.html </p>
